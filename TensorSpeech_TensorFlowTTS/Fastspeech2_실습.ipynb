{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Fastspeech2_실습.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNraq8+v3k0sgE69Ce7zszX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uRG9wdMFnyDX"},"source":["# Fastspeech2 해설 및 실습"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VNbS7-vHvtkH","executionInfo":{"status":"ok","timestamp":1633325802616,"user_tz":-540,"elapsed":2235,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"2294eca0-f098-4897-bd14-2b3ee9442305"},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["2.6.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Qfqry27Gnmg6","executionInfo":{"status":"ok","timestamp":1633325802617,"user_tz":-540,"elapsed":6,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"4021e24e-2e09-4074-dca4-40a9b83894f4"},"source":["# -*- coding: utf-8 -*-\n","# Copyright 2020 The FastSpeech2 Authors and Minh Nguyen (@dathudeptrai)\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\"Tensorflow Model modules for FastSpeech2.\"\"\""],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tensorflow Model modules for FastSpeech2.'"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"MiM6EvUepXWf","executionInfo":{"status":"ok","timestamp":1633325902464,"user_tz":-540,"elapsed":99851,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"5563caf6-0ded-4619-8ee1-4ecdb4eca139"},"source":["!pip install TensorFlowTTS"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting TensorFlowTTS\n","  Downloading TensorFlowTTS-1.8-py3-none-any.whl (128 kB)\n","\u001b[?25l\r\u001b[K     |██▌                             | 10 kB 20.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 20 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 30 kB 20.1 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 40 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 51 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 61 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 128 kB 5.4 MB/s \n","\u001b[?25hCollecting g2p-en\n","  Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 28.9 MB/s \n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from TensorFlowTTS) (7.1.2)\n","Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from TensorFlowTTS) (3.1.0)\n","Collecting tensorflow-gpu==2.6.0\n","  Downloading tensorflow_gpu-2.6.0-cp37-cp37m-manylinux2010_x86_64.whl (458.3 MB)\n","\u001b[K     |████████████████████████████████| 458.3 MB 10 kB/s \n","\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from TensorFlowTTS) (3.13)\n","Collecting textgrid\n","  Downloading TextGrid-1.5-py3-none-any.whl (10.0 kB)\n","Requirement already satisfied: tqdm>=4.26.1 in /usr/local/lib/python3.7/dist-packages (from TensorFlowTTS) (4.62.3)\n","Collecting huggingface-hub==0.0.8\n","  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n","Collecting pyworld>=0.2.10\n","  Downloading pyworld-0.3.0.tar.gz (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 41.8 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting g2pM\n","  Downloading g2pM-0.1.2.5-py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 38.7 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from TensorFlowTTS) (3.2.2)\n","Collecting inflect>=4.1.0\n","  Downloading inflect-5.3.0-py3-none-any.whl (32 kB)\n","Collecting pypinyin\n","  Downloading pypinyin-0.42.1-py2.py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 39.3 MB/s \n","\u001b[?25hCollecting numba<=0.48\n","  Downloading numba-0.48.0-1-cp37-cp37m-manylinux2014_x86_64.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 32.5 MB/s \n","\u001b[?25hRequirement already satisfied: librosa>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from TensorFlowTTS) (0.8.1)\n","Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from TensorFlowTTS) (0.22.2.post1)\n","Collecting tensorflow-addons>=0.10.0\n","  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 45.2 MB/s \n","\u001b[?25hCollecting unidecode>=1.1.1\n","  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n","\u001b[K     |████████████████████████████████| 235 kB 43.0 MB/s \n","\u001b[?25hCollecting jamo>=0.4.1\n","  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n","Collecting dataclasses\n","  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n","Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from TensorFlowTTS) (0.10.3.post1)\n","Requirement already satisfied: setuptools>=38.5.1 in /usr/local/lib/python3.7/dist-packages (from TensorFlowTTS) (57.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.8->TensorFlowTTS) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.8->TensorFlowTTS) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.8->TensorFlowTTS) (4.8.1)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (1.6.3)\n","Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (1.19.5)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (1.12.1)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (2.6.0)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (0.12.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (3.17.3)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (1.1.2)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (0.4.0)\n","Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (2.6.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (3.7.4.3)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (0.2.0)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (1.15.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (3.3.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (1.12)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (1.1.0)\n","Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (1.40.0)\n","Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (5.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (0.37.0)\n","Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.6.0->TensorFlowTTS) (2.6.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.10.0->TensorFlowTTS) (1.5.2)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->TensorFlowTTS) (2.1.9)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->TensorFlowTTS) (1.5.1)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->TensorFlowTTS) (4.4.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->TensorFlowTTS) (21.0)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->TensorFlowTTS) (0.2.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->TensorFlowTTS) (1.0.1)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.7.0->TensorFlowTTS) (1.4.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->TensorFlowTTS) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->TensorFlowTTS) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->TensorFlowTTS) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->TensorFlowTTS) (1.3.2)\n","Collecting llvmlite<0.32.0,>=0.31.0dev0\n","  Downloading llvmlite-0.31.0-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n","\u001b[K     |████████████████████████████████| 20.2 MB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.7.0->TensorFlowTTS) (1.4.4)\n","Requirement already satisfied: cython>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from pyworld>=0.2.10->TensorFlowTTS) (0.29.24)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->TensorFlowTTS) (1.14.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->TensorFlowTTS) (2.20)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS) (3.3.4)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS) (0.6.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS) (1.8.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS) (4.2.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub==0.0.8->TensorFlowTTS) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub==0.0.8->TensorFlowTTS) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub==0.0.8->TensorFlowTTS) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub==0.0.8->TensorFlowTTS) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu==2.6.0->TensorFlowTTS) (3.1.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons>=0.10.0->TensorFlowTTS) (2.7.1)\n","Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.7/dist-packages (from g2p-en->TensorFlowTTS) (3.2.5)\n","Collecting distance>=0.1.3\n","  Downloading Distance-0.1.3.tar.gz (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 41.1 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub==0.0.8->TensorFlowTTS) (3.5.0)\n","Building wheels for collected packages: pyworld, distance\n","  Building wheel for pyworld (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyworld: filename=pyworld-0.3.0-cp37-cp37m-linux_x86_64.whl size=609651 sha256=15dbdba6a237a0c7e6eeb7a6d408d565bf7c7789e6edee943c7fc4f14ec63c12\n","  Stored in directory: /root/.cache/pip/wheels/e7/7c/11/c775fffa0e1e7b05a6604b4323408a77f80fb4ab304d96b5c6\n","  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16275 sha256=d0365c860d5207b88c4ba4c3e588bbb50d2ad594fe1616798b1c8180edef7102\n","  Stored in directory: /root/.cache/pip/wheels/b2/10/1b/96fca621a1be378e2fe104cfb0d160bb6cdf3d04a3d35266cc\n","Successfully built pyworld distance\n","Installing collected packages: llvmlite, numba, inflect, distance, unidecode, textgrid, tensorflow-gpu, tensorflow-addons, pyworld, pypinyin, jamo, huggingface-hub, g2pM, g2p-en, dataclasses, TensorFlowTTS\n","  Attempting uninstall: llvmlite\n","    Found existing installation: llvmlite 0.34.0\n","    Uninstalling llvmlite-0.34.0:\n","      Successfully uninstalled llvmlite-0.34.0\n","  Attempting uninstall: numba\n","    Found existing installation: numba 0.51.2\n","    Uninstalling numba-0.51.2:\n","      Successfully uninstalled numba-0.51.2\n","  Attempting uninstall: inflect\n","    Found existing installation: inflect 2.1.0\n","    Uninstalling inflect-2.1.0:\n","      Successfully uninstalled inflect-2.1.0\n","Successfully installed TensorFlowTTS-1.8 dataclasses-0.6 distance-0.1.3 g2p-en-2.1.0 g2pM-0.1.2.5 huggingface-hub-0.0.8 inflect-5.3.0 jamo-0.4.1 llvmlite-0.31.0 numba-0.48.0 pypinyin-0.42.1 pyworld-0.3.0 tensorflow-addons-0.14.0 tensorflow-gpu-2.6.0 textgrid-1.5 unidecode-1.3.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tensorflow"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iz04_PmStxum","executionInfo":{"status":"ok","timestamp":1633326027391,"user_tz":-540,"elapsed":124931,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"e7d81ba1-7a86-4aa0-f48d-fcd2319adddd"},"source":["# Mount Google Drive to VM instance.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!git clone https://github.com/TensorSpeech/TensorFlowTTS.git"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Cloning into 'TensorFlowTTS'...\n","remote: Enumerating objects: 10609, done.\u001b[K\n","remote: Counting objects: 100% (319/319), done.\u001b[K\n","remote: Compressing objects: 100% (162/162), done.\u001b[K\n","remote: Total 10609 (delta 183), reused 233 (delta 152), pack-reused 10290\u001b[K\n","Receiving objects: 100% (10609/10609), 133.30 MiB | 27.18 MiB/s, done.\n","Resolving deltas: 100% (5123/5123), done.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":653},"id":"K7p_9PjpzKCc","executionInfo":{"status":"ok","timestamp":1633326036074,"user_tz":-540,"elapsed":8686,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"d27fbad8-4525-419a-9310-59ec9a6cf6de"},"source":["!pip install h5py==2.10\n","!pip install git+https://github.com/repodiac/german_transliterate\n","\"\"\"\n","HDF5(계층적데이터형식, 빅데이터 처리를 위한 파일 형식)을 python에서 사용하기 위한 모듈\n","독일어 자역 모듈\n","약어, 숫자, 타임 스탬프 등을 포함한 독일어 텍스트를 정리하고 음역 (예 : 정규화)하는 Python 모듈\n","\"\"\""],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting h5py==2.10\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10) (1.15.0)\n","Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10) (1.19.5)\n","Installing collected packages: h5py\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.6.0 requires h5py~=3.1.0, but you have h5py 2.10.0 which is incompatible.\n","tensorflow-gpu 2.6.0 requires h5py~=3.1.0, but you have h5py 2.10.0 which is incompatible.\u001b[0m\n","Successfully installed h5py-2.10.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["h5py"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/repodiac/german_transliterate\n","  Cloning https://github.com/repodiac/german_transliterate to /tmp/pip-req-build-7dzisb62\n","  Running command git clone -q https://github.com/repodiac/german_transliterate /tmp/pip-req-build-7dzisb62\n","Collecting num2words\n","  Downloading num2words-0.5.10-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 4.4 MB/s \n","\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words->german-transliterate==0.1.3) (0.6.2)\n","Building wheels for collected packages: german-transliterate\n","  Building wheel for german-transliterate (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for german-transliterate: filename=german_transliterate-0.1.3-py3-none-any.whl size=20830 sha256=7aa948466b4350274de085a1e052391677c52a8defea0f361b6992955dff0516\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-8amlmusx/wheels/67/99/62/1f618221d7d4275595cf736d3e2d587b64bf427571c9b9a84d\n","Successfully built german-transliterate\n","Installing collected packages: num2words, german-transliterate\n","Successfully installed german-transliterate-0.1.3 num2words-0.5.10\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nHDF5(계층적데이터형식, 빅데이터 처리를 위한 파일 형식)을 python에서 사용하기 위한 모듈\\n독일어 자역 모듈\\n약어, 숫자, 타임 스탬프 등을 포함한 독일어 텍스트를 정리하고 음역 (예 : 정규화)하는 Python 모듈\\n'"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"Lw7HMo6_t5gl","executionInfo":{"status":"ok","timestamp":1633331057873,"user_tz":-540,"elapsed":421,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}}},"source":["import tensorflow as tf\n","from tensorflow_tts.models.fastspeech import TFFastSpeech, get_initializer"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HyVWNfUODOov"},"source":["## TFFastSpeechVariantPredictor 클래스"]},{"cell_type":"code","metadata":{"id":"Jf95qdai7VMq","executionInfo":{"status":"ok","timestamp":1633331060342,"user_tz":-540,"elapsed":266,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}}},"source":["# fastspeech 예측 모델 (keras.layers.Layer에서 상속받은 객체)\n","class TFFastSpeechVariantPredictor(tf.keras.layers.Layer):\n","    \"\"\"FastSpeech duration predictor module.\"\"\"\n","\n","    def __init__(self, config, **kwargs):\n","        \"\"\"Init variables.\"\"\"\n","        super().__init__(**kwargs)\n","        # 상속받은 class의 생성자를 호출하기 위해서 super를 씀\n","        \n","        self.conv_layers = []\n","        \n","        # 합성곱 레이어 생성 \n","        for i in range(config.variant_prediction_num_conv_layers):\n","            # config.variant_prediction_num_conv_layers의 숫자만큼\n","            self.conv_layers.append(\n","                tf.keras.layers.Conv1D(\n","                    config.variant_predictor_filter, # Conv 필터\n","                    config.variant_predictor_kernel_size, # kernel 사이즈 값\n","                    padding=\"same\", # 패딩은 입출력이 동일하게 만듬\n","                    name=\"conv_._{}\".format(i),\n","                )\n","            )\n","            self.conv_layers.append(tf.keras.layers.Activation(tf.nn.relu))\n","            # 활성함수는 relu 사용\n","\n","            self.conv_layers.append(\n","                tf.keras.layers.LayerNormalization(\n","                    # 정규화 설정\n","                    epsilon=config.layer_norm_eps, name=\"LayerNorm_._{}\".format(i)\n","                    # epsilon =  0으로 나누는 것을 피하기 위해 분산에 작은 부동 소수점이 추가\n","                )\n","            )\n","            self.conv_layers.append(\n","                tf.keras.layers.Dropout(config.variant_predictor_dropout_rate)\n","                # Dropout 설정\n","            )\n","        self.conv_layers_sequence = tf.keras.Sequential(self.conv_layers)\n","        # conv_sequence에 Sequential객체 담음\n","\n","        self.output_layer = tf.keras.layers.Dense(1)\n","        # 마지막 output_layer에는 하나의 Dense레이어를 삽입\n","\n","        if config.n_speakers > 1:\n","            # 만약 n_speakers가 있다면 임베딩 벡터를 만들기위한 임베딩 레이어 삽입\n","            \n","            # 디코더에 들어갈 임베딩레이어\n","            self.decoder_speaker_embeddings = tf.keras.layers.Embedding(\n","                config.n_speakers,\n","                config.encoder_self_attention_params.hidden_size,\n","                # 히든 스테이트 사이즈 지정\n","                embeddings_initializer=get_initializer(config.initializer_range),\n","                # 임베딩 초기화 (설정값대로?)\n","                name=\"speaker_embeddings\",\n","            )\n","            # speaker_fc? Dense 레이어에 self_attention의 히든 스테이트 사이즈 지정\n","            self.speaker_fc = tf.keras.layers.Dense(\n","                units=config.encoder_self_attention_params.hidden_size,\n","                name=\"speaker_fc\",\n","            )\n","        # 환경 설정\n","        self.config = config"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"swzU0cy5DSN4"},"source":["## Call 함수"]},{"cell_type":"code","metadata":{"id":"BxPUQRe7Bbn4","executionInfo":{"status":"ok","timestamp":1633331062352,"user_tz":-540,"elapsed":375,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}}},"source":["    # 로직 불러오기 (call 메서드)\n","    def call(self, inputs, training=False):\n","        # 새로 학습하지 않고 사용 training=False\n","\n","        \"\"\"Call logic.\"\"\"\n","        encoder_hidden_states, speaker_ids, attention_mask = inputs\n","        # encoder_hidden_states, speaker_ids, attention_mask 지정\n","        # speaker_ids 는 화자 아이디\n","\n","        attention_mask = tf.cast(\n","            tf.expand_dims(attention_mask, 2), encoder_hidden_states.dtype\n","            # attantion_mask에 2차원 추가하고 encoder_hidden_states와 dtype 맞춤\n","        )\n","\n","        if self.config.n_speakers > 1:\n","            speaker_embeddings = self.decoder_speaker_embeddings(speaker_ids)\n","            # 임베딩 벡터화?\n","            speaker_features = tf.math.softplus(self.speaker_fc(speaker_embeddings))\n","            # softplus계산을 통해 특성을 뽑아냄\n","\n","            # extended speaker embeddings\n","            # speaker 임베딩을 확장\n","            extended_speaker_features = speaker_features[:, tf.newaxis, :]\n","            # speaker_features 1차원 추가\n","\n","            encoder_hidden_states += extended_speaker_features\n","            # speaker_features 만큼 hidden_states 추가\n","\n","        # mask encoder hidden states\n","        masked_encoder_hidden_states = encoder_hidden_states * attention_mask\n","        # encoder_hidden_states * attention_mask을 엘레먼트 와이즈하여 mask를 씌워줌\n","\n","        # pass though first layer\n","        # 첫번째 층 통과\n","        outputs = self.conv_layers_sequence(masked_encoder_hidden_states)\n","        outputs = self.output_layer(outputs)\n","        masked_outputs = outputs * attention_mask\n","        # outputs 에 mask를 씌워줌\n","\n","        print('masked_outputs : ', masked_outputs.shape)\n","        outputs = tf.squeeze(masked_outputs, -1)\n","        print('outputs : ', outputs.shape)\n","        # -1 치수 값 제거\n","        return outputs"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oi39c9qqDKW4"},"source":["## TFFastSpeech2 클래스"]},{"cell_type":"code","metadata":{"id":"kGjUKWgCCkKo","executionInfo":{"status":"ok","timestamp":1633331064164,"user_tz":-540,"elapsed":417,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}}},"source":["# TFFastSpeech를 상속받은 FastSpeech2 클래스\n","class TFFastSpeech2(TFFastSpeech):\n","    \"\"\"TF Fastspeech module.\"\"\"\n","\n","    def __init__(self, config, **kwargs):\n","        \"\"\"Init layers for fastspeech.\"\"\"\n","        super().__init__(config, **kwargs)\n","        self.f0_predictor = TFFastSpeechVariantPredictor(\n","            config, dtype=tf.float32, name=\"f0_predictor\"\n","        ) # f0_predictor = TFFastSpeechVariantPredictor 상속\n","\n","        self.energy_predictor = TFFastSpeechVariantPredictor(\n","            config, dtype=tf.float32, name=\"energy_predictor\",\n","        ) # energy_predictor = TFFastSpeechVariantPredictor 상속\n","\n","        self.duration_predictor = TFFastSpeechVariantPredictor(\n","            config, dtype=tf.float32, name=\"duration_predictor\"\n","        ) # duration_predictor = TFFastSpeechVariantPredictor 상속\n","\n","        # define f0_embeddings and energy_embeddings\n","        # f0_embeddings 과 energy_embeddings를 정의\n","        self.f0_embeddings = tf.keras.layers.Conv1D(\n","            filters=config.encoder_self_attention_params.hidden_size,\n","            kernel_size=9,\n","            padding=\"same\",\n","            name=\"f0_embeddings\",\n","        ) # f0_embeddings에 Conv레이어 삽입\n","\n","        self.f0_dropout = tf.keras.layers.Dropout(0.5)\n","        # Dropout은 50%\n","\n","        self.energy_embeddings = tf.keras.layers.Conv1D(\n","            filters=config.encoder_self_attention_params.hidden_size,\n","            kernel_size=9,\n","            padding=\"same\",\n","            name=\"energy_embeddings\",\n","        ) # energy_embeddings Conv 레이어 삽입\n","\n","        self.energy_dropout = tf.keras.layers.Dropout(0.5)\n","        # Dropout은 50%"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UH4PtAE1DaeY"},"source":["## build 함수"]},{"cell_type":"code","metadata":{"id":"mVWLMnSTDiZ0","executionInfo":{"status":"ok","timestamp":1633331065893,"user_tz":-540,"elapsed":1,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}}},"source":["    # 빌드 메서드\n","    def _build(self):\n","        \"\"\"Dummy input for building model.\"\"\"\n","        # fake inputs\n","        input_ids = tf.convert_to_tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]], tf.int32)\n","        # value값을 tensor로 변환, input_ids값 지정\n","        \n","        speaker_ids = tf.convert_to_tensor([0], tf.int32)\n","        # speaker_ids값 지정\n","\n","        duration_gts = tf.convert_to_tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], tf.int32)\n","        # duration_gts 지정\n","\n","        f0_gts = tf.convert_to_tensor(\n","            [[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]], tf.float32\n","        ) # f0_gts 지정\n","\n","        energy_gts = tf.convert_to_tensor(\n","            [[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]], tf.float32\n","        ) # energy_gts 지정\n","\n","        self(\n","            input_ids=input_ids,\n","            speaker_ids=speaker_ids,\n","            duration_gts=duration_gts,\n","            f0_gts=f0_gts,\n","            energy_gts=energy_gts,\n","        )"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JgDoK-5zDly4"},"source":["## call 함수"]},{"cell_type":"code","metadata":{"id":"LAr7zESPKG2P","executionInfo":{"status":"ok","timestamp":1633331739323,"user_tz":-540,"elapsed":421,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}}},"source":["    def call( # 들어가는 변수가 무엇인지 모르겟음\n","        self,\n","        input_ids,\n","        speaker_ids, # 화자의 수 \n","        duration_gts,\n","        f0_gts,\n","        energy_gts,\n","        training=False,\n","        **kwargs,\n","    ):\n","        \"\"\"Call logic.\"\"\"\n","        attention_mask = tf.math.not_equal(input_ids, 0)\n","        # input_ids 와 0을 비교하여 True, False값으로 attention_mask 만듬\n","\n","        embedding_output = self.embeddings([input_ids, speaker_ids], training=training)\n","        # 임베딩 output\n","\n","        encoder_output = self.encoder(\n","            [embedding_output, attention_mask], training=training\n","        ) # 인코더 output\n","\n","        last_encoder_hidden_states = encoder_output[0]\n","        # encoder_output의 열개수로 last_encoder_hidden_states를 지정\n","\n","        # energy predictor, here use last_encoder_hidden_states, u can use more hidden_states layers\n","        # energy predictor, 여기서는 last_contain_hidden_states 사용,  더 많은 hidden_states 레이어를 사용할 수 있습니다.\n","\n","        # rather than just use last_hidden_states of encoder for energy_predictor.\n","        # energy_didden_states를 위해 인코더의 last_hidden_states만 사용하는 것이 아니라\n","        duration_outputs = self.duration_predictor(\n","            [last_encoder_hidden_states, speaker_ids, attention_mask]\n","        )  # [batch_size, length]\n","        # duration_predictor 통해 duration_outputs 지정\n","\n","        f0_outputs = self.f0_predictor(\n","            [last_encoder_hidden_states, speaker_ids, attention_mask], training=training\n","        ) # f0_predictor로 f0_outputs 지정\n","\n","        energy_outputs = self.energy_predictor(\n","            [last_encoder_hidden_states, speaker_ids, attention_mask], training=training\n","        ) # energy_predictor로 energy_outputs 지정\n","\n","        f0_embedding = self.f0_embeddings(\n","            tf.expand_dims(f0_gts, 2)\n","            # f0_gts, 2차원 추가\n","        )  # [barch_size, mel_length, feature]\n","\n","        energy_embedding = self.energy_embeddings(\n","            tf.expand_dims(energy_gts, 2)\n","            # energy_gts, 2차원 추가\n","        )  # [barch_size, mel_length, feature]\n","\n","        # apply dropout both training/inference\n","        # training/inference 둘다 dropout 적용\n","        f0_embedding = self.f0_dropout(f0_embedding, training=True)\n","        energy_embedding = self.energy_dropout(energy_embedding, training=True)\n","\n","        # sum features\n","        # 특성값의 합\n","        last_encoder_hidden_states += f0_embedding + energy_embedding\n","        # f0_embedding + energy_embedding 값을 last_encoder_hidden_states에 추가\n","\n","        # 범위 조절 output\n","        length_regulator_outputs, encoder_masks = self.length_regulator(\n","            [last_encoder_hidden_states, duration_gts], training=training\n","        )\n","\n","        # create decoder positional embedding\n","        # 디코더 포지션임베딩 생성\n","        decoder_pos = tf.range(\n","            1, tf.shape(length_regulator_outputs)[1] + 1, dtype=tf.int32\n","        )\n","        masked_decoder_pos = tf.expand_dims(decoder_pos, 0) * encoder_masks\n","        # decoder_pos에 차원을 늘리고 mask를 씌움\n","\n","        decoder_output = self.decoder(\n","            [length_regulator_outputs, speaker_ids, encoder_masks, masked_decoder_pos],\n","            training=training,\n","        ) # 디코더의 output을 지정\n","\n","        last_decoder_hidden_states = decoder_output[0]\n","        # last_decoder_hidden_states는 디코더의 output의 열개수 만큼으로 지정\n","\n","        # here u can use sum or concat more than 1 hidden states layers from decoder.\n","        # 여기서 당신은 디코더에서 둘 이상의 숨겨진 상태 레이어를 사용할 수 있다.\n","        mels_before = self.mel_dense(last_decoder_hidden_states)\n","        mels_after = (\n","            self.postnet([mels_before, encoder_masks], training=training) + mels_before\n","        )\n","\n","        # ouptputs 지정\n","        outputs = (\n","            mels_before,\n","            mels_after,\n","            duration_outputs,\n","            f0_outputs,\n","            energy_outputs,\n","        )\n","        return outputs"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XxYiPPUTKIcm"},"source":["## inference 함수 (추론)"]},{"cell_type":"code","metadata":{"id":"kvwLsGRjQ9YE","executionInfo":{"status":"ok","timestamp":1633333535275,"user_tz":-540,"elapsed":268,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}}},"source":["    # _inference 메서드\n","    def _inference(\n","        self,\n","        input_ids, # input 값\n","        speaker_ids, # 화자의 수\n","        speed_ratios, # 속도율\n","        f0_ratios,\n","        energy_ratios, # 에너지율\n","        **kwargs,\n","    ):\n","        \"\"\"Call logic.\"\"\"\n","        attention_mask = tf.math.not_equal(input_ids, 0)\n","        # input_ids, 0을 비교하여 True, False값으로 attention_mask 생성\n","\n","        embedding_output = self.embeddings([input_ids, speaker_ids], training=False)\n","        # input값과 화자의수로 임베딩\n","\n","        encoder_output = self.encoder(\n","            [embedding_output, attention_mask], training=False\n","        ) # 임베딩된 값과 mask한 값을 인코딩함\n","\n","        last_encoder_hidden_states = encoder_output[0]\n","        # last_encoder_hidden_states는 인코더의 output의 열개수로 지정\n","\n","        # expand ratios\n","        # 비율 확장\n","        speed_ratios = tf.expand_dims(speed_ratios, 1)  # [B, 1]\n","        f0_ratios = tf.expand_dims(f0_ratios, 1)  # [B, 1]\n","        energy_ratios = tf.expand_dims(energy_ratios, 1)  # [B, 1]\n","\n","        # energy predictor, here use last_encoder_hidden_states, u can use more hidden_states layers\n","        # energy predictor, 여기서는 last_contain_hidden_states 사용, 더 많은 hidden_states 레이어를 사용할 수 있습니다.\n","\n","        # rather than just use last_hidden_states of encoder for energy_predictor.\n","        # energy_didden_states를 위해 인코더의 last_hidden_states만 사용하는 것이 아니라\n","\n","        duration_outputs = self.duration_predictor(\n","            # 지속 시간 예측\n","\n","            [last_encoder_hidden_states, speaker_ids, attention_mask]\n","        )  # [batch_size, length]\n","\n","        duration_outputs = tf.nn.relu(tf.math.exp(duration_outputs) - 1.0)\n","        # 지수 값을 계산 - 1.0 을 relu로 계산\n","\n","        duration_outputs = tf.cast(\n","            tf.math.round(duration_outputs * speed_ratios), tf.int32\n","        ) # (duration_outputs * speed_ratios) 반올림하여 int형변환\n","\n","        f0_outputs = self.f0_predictor(\n","            [last_encoder_hidden_states, speaker_ids, attention_mask], training=False\n","        ) # f0_outputs 지정\n","        \n","        f0_outputs *= f0_ratios\n","        # f0_outputs에 f0_ratios를 곱해줌\n","        \n","        energy_outputs = self.energy_predictor(\n","            [last_encoder_hidden_states, speaker_ids, attention_mask], training=False\n","        ) # energy_outputs 지정\n","\n","        energy_outputs *= energy_ratios\n","        # energy_outputs에 energy_ratios를 곱해줌\n","\n","        f0_embedding = self.f0_dropout(\n","            self.f0_embeddings(tf.expand_dims(f0_outputs, 2)), training=True\n","        ) # f0_embedding 지정 (dropout)\n","\n","        energy_embedding = self.energy_dropout(\n","            self.energy_embeddings(tf.expand_dims(energy_outputs, 2)), training=True\n","        ) # energy_embedding 지정 (dropout)\n","\n","        # sum features\n","        last_encoder_hidden_states += f0_embedding + energy_embedding\n","        # f0_embedding + energy_embedding 값을 last_encoder_hidden_states 추가\n","\n","        length_regulator_outputs, encoder_masks = self.length_regulator(\n","            [last_encoder_hidden_states, duration_outputs], training=False\n","        ) # 길이 조절\n","\n","        # create decoder positional embedding\n","        # 디코더 포지션임베딩 생성\n","        decoder_pos = tf.range(\n","            1, tf.shape(length_regulator_outputs)[1] + 1, dtype=tf.int32\n","        ) # decoder_pos 지정\n","\n","        masked_decoder_pos = tf.expand_dims(decoder_pos, 0) * encoder_masks\n","        # decoder_pos 에 mask 씌움\n","\n","        decoder_output = self.decoder(\n","            [length_regulator_outputs, speaker_ids, encoder_masks, masked_decoder_pos],\n","            training=False,\n","        ) # 디코더 진행\n","\n","        last_decoder_hidden_states = decoder_output[0]\n","        # last_decoder_hidden_states는 디코더output의 열개수\n","\n","        # here u can use sum or concat more than 1 hidden states layers from decoder.\n","        # 여기서 당신은 디코더에서 둘 이상의 숨겨진 상태 레이어를 사용할 수 있다.\n","        mel_before = self.mel_dense(last_decoder_hidden_states)\n","        mel_after = (\n","            self.postnet([mel_before, encoder_masks], training=False) + mel_before\n","        ) # postnet + mel_dense로 mel_after 생성\n","\n","        outputs = (mel_before, mel_after, duration_outputs, f0_outputs, energy_outputs)\n","        return outputs"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m3KvxiuIRAeE"},"source":["## setup_inference_fn 함수"]},{"cell_type":"code","metadata":{"id":"AWwP4BgioGRv","executionInfo":{"status":"ok","timestamp":1633331255618,"user_tz":-540,"elapsed":458,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}}},"source":["    # setup_inference_fn 메서드\n","    def setup_inference_fn(self):\n","        self.inference = tf.function( # tf.function 함수를 활용하여 호출 가능한 TensorFlow 그래프로 컴파일합니다.\n","            self._inference,\n","            experimental_relax_shapes=True,\n","            # True면, tf.function은 더 적게 즉, 입력 모양에서 덜 다루어지는 그래프를 생성\n","\n","            input_signature=[ \n","                # 입력 시그니쳐(signature)에 대해 초기화 (텐서의 모양으로 전달)\n","                tf.TensorSpec(shape=[None, None], dtype=tf.int32, name=\"input_ids\"),\n","                tf.TensorSpec(shape=[None,], dtype=tf.int32, name=\"speaker_ids\"),\n","                tf.TensorSpec(shape=[None,], dtype=tf.float32, name=\"speed_ratios\"),\n","                tf.TensorSpec(shape=[None,], dtype=tf.float32, name=\"f0_ratios\"),\n","                tf.TensorSpec(shape=[None,], dtype=tf.float32, name=\"energy_ratios\"),\n","            ],\n","        )\n","\n","        self.inference_tflite = tf.function(\n","            self._inference,\n","            experimental_relax_shapes=True,\n","            # True면, tf.function은 더 적게 즉, 입력 모양에서 덜 다루어지는 그래프를 생성\n","            input_signature=[\n","                # 입력 시그니쳐(signature)에 대해 초기화 (텐서의 모양으로 전달)\n","                tf.TensorSpec(shape=[1, None], dtype=tf.int32, name=\"input_ids\"),\n","                tf.TensorSpec(shape=[1,], dtype=tf.int32, name=\"speaker_ids\"),\n","                tf.TensorSpec(shape=[1,], dtype=tf.float32, name=\"speed_ratios\"),\n","                tf.TensorSpec(shape=[1,], dtype=tf.float32, name=\"f0_ratios\"),\n","                tf.TensorSpec(shape=[1,], dtype=tf.float32, name=\"energy_ratios\"),\n","            ],\n","        )"],"execution_count":19,"outputs":[]}]}